{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e8e6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/06 08:38:12 WARN Utils: Your hostname, prabhu resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/09/06 08:38:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "25/09/06 08:38:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.app.id: local-1757147897498\n",
      "spark.app.startTime: 1757147896025\n",
      "spark.rdd.compress: True\n",
      "spark.driver.port: 42127\n",
      "spark.serializer.objectStreamReset: 100\n",
      "spark.master: local[*]\n",
      "spark.submit.pyFiles: \n",
      "spark.executor.id: driver\n",
      "spark.submit.deployMode: client\n",
      "spark.driver.host: 10.255.255.254\n",
      "spark.app.name: handling complex data types\n",
      "spark.ui.showConsoleProgress: true\n",
      "Spark Job URL: http://10.255.255.254:4040\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init(spark_home=\"/home/prabhakar/mybin/spark-3.0.2-bin-hadoop2.7-hive1.2\")\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"handling complex data types\").getOrCreate()\n",
    "\n",
    "\n",
    "configs = spark.sparkContext.getConf().getAll()\n",
    "for key, value in configs:\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Get the Spark UI URL\n",
    "spark_ui_url = spark.sparkContext.uiWebUrl\n",
    "\n",
    "print(f\"Spark Job URL: {spark_ui_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9f3ad8",
   "metadata": {},
   "source": [
    "### Explode Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "626a9041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+-----------------------------------------------+\n",
      "|order_id|customer_id|order_date|items                                          |\n",
      "+--------+-----------+----------+-----------------------------------------------+\n",
      "|ORD001  |CUST1001   |2023-10-01|[[P100, Laptop, 1, 1000], [P200, Mouse, 2, 25]]|\n",
      "|ORD002  |CUST1002   |2023-10-02|[[P300, Monitor, 1, 300]]                      |\n",
      "|ORD003  |CUST1003   |2023-10-03|[]                                             |\n",
      "+--------+-----------+----------+-----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    {\n",
    "        \"order_id\": \"ORD001\",\n",
    "        \"customer_id\": \"CUST1001\",\n",
    "        \"order_date\": \"2023-10-01\",\n",
    "        \"items\": [\n",
    "            {\"product_id\": \"P100\", \"product_name\": \"Laptop\", \"quantity\": 1, \"price\": 1000},\n",
    "            {\"product_id\": \"P200\", \"product_name\": \"Mouse\", \"quantity\": 2, \"price\": 25}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"order_id\": \"ORD002\",\n",
    "        \"customer_id\": \"CUST1002\",\n",
    "        \"order_date\": \"2023-10-02\",\n",
    "        \"items\": [\n",
    "            {\"product_id\": \"P300\", \"product_name\": \"Monitor\", \"quantity\": 1, \"price\": 300}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"order_id\": \"ORD003\",\n",
    "        \"customer_id\": \"CUST1003\",\n",
    "        \"order_date\": \"2023-10-03\",\n",
    "        \"items\": []\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"order_id\", StringType(), True),\n",
    "    StructField(\"customer_id\", StringType(), True),\n",
    "    StructField(\"order_date\", StringType(), True),\n",
    "    StructField(\"items\", ArrayType(\n",
    "        StructType([\n",
    "            StructField(\"product_id\", StringType(), True),\n",
    "            StructField(\"product_name\", StringType(), True),\n",
    "            StructField(\"quantity\", IntegerType(), True),\n",
    "            StructField(\"price\", IntegerType(), True)\n",
    "        ])\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "df.show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cec7305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- items: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- product_id: string (nullable = true)\n",
      " |    |    |-- product_name: string (nullable = true)\n",
      " |    |    |-- quantity: integer (nullable = true)\n",
      " |    |    |-- price: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8851e4b7",
   "metadata": {},
   "source": [
    "### Q: What is the total quantity per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f0add92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "# df2 = df.withColumn(\"exp_items\", explode(col(\"items\")))\n",
    "# df2 = df.withColumn(\"exp_items\", explode(df[\"items\"]))\n",
    "df2 = df.withColumn(\"exp_items\", explode(df.items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "666367a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- items: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- product_id: string (nullable = true)\n",
      " |    |    |-- product_name: string (nullable = true)\n",
      " |    |    |-- quantity: integer (nullable = true)\n",
      " |    |    |-- price: integer (nullable = true)\n",
      " |-- exp_items: struct (nullable = true)\n",
      " |    |-- product_id: string (nullable = true)\n",
      " |    |-- product_name: string (nullable = true)\n",
      " |    |-- quantity: integer (nullable = true)\n",
      " |    |-- price: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afa86e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+-----------------------------------------------+\n",
      "|order_id|customer_id|order_date|items                                          |\n",
      "+--------+-----------+----------+-----------------------------------------------+\n",
      "|ORD001  |CUST1001   |2023-10-01|[[P100, Laptop, 1, 1000], [P200, Mouse, 2, 25]]|\n",
      "|ORD002  |CUST1002   |2023-10-02|[[P300, Monitor, 1, 300]]                      |\n",
      "|ORD003  |CUST1003   |2023-10-03|[]                                             |\n",
      "+--------+-----------+----------+-----------------------------------------------+\n",
      "\n",
      "+--------+-----------+----------+-----------------------------------------------+-----------------------+\n",
      "|order_id|customer_id|order_date|items                                          |exp_items              |\n",
      "+--------+-----------+----------+-----------------------------------------------+-----------------------+\n",
      "|ORD001  |CUST1001   |2023-10-01|[[P100, Laptop, 1, 1000], [P200, Mouse, 2, 25]]|[P100, Laptop, 1, 1000]|\n",
      "|ORD001  |CUST1001   |2023-10-01|[[P100, Laptop, 1, 1000], [P200, Mouse, 2, 25]]|[P200, Mouse, 2, 25]   |\n",
      "|ORD002  |CUST1002   |2023-10-02|[[P300, Monitor, 1, 300]]                      |[P300, Monitor, 1, 300]|\n",
      "+--------+-----------+----------+-----------------------------------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28ccee5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|order_date|quantity|\n",
      "+----------+--------+\n",
      "|2023-10-01|       1|\n",
      "|2023-10-01|       2|\n",
      "|2023-10-02|       1|\n",
      "+----------+--------+\n",
      "\n",
      "+----------+-----------------------+\n",
      "|order_date|sum(exp_items.quantity)|\n",
      "+----------+-----------------------+\n",
      "|2023-10-02|                      1|\n",
      "|2023-10-01|                      3|\n",
      "+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(col(\"order_date\"), col(\"exp_items.quantity\")).show()\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "df2.groupBy(col(\"order_date\")).agg(F.sum(\"exp_items.quantity\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c2d567",
   "metadata": {},
   "source": [
    "### explode_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0fa493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode_outer\n",
    "# df3 = df.withColumn(\"exp_items\", explode(col(\"items\")))\n",
    "# df3 = df.withColumn(\"exp_items\", explode(df[\"items\"]))\n",
    "df3 = df.withColumn(\"exp_items\", explode_outer(df.items)) # ---> explode_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a41c2e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+-----------------------------------------------+\n",
      "|order_id|customer_id|order_date|items                                          |\n",
      "+--------+-----------+----------+-----------------------------------------------+\n",
      "|ORD001  |CUST1001   |2023-10-01|[[P100, Laptop, 1, 1000], [P200, Mouse, 2, 25]]|\n",
      "|ORD002  |CUST1002   |2023-10-02|[[P300, Monitor, 1, 300]]                      |\n",
      "|ORD003  |CUST1003   |2023-10-03|[]                                             |\n",
      "+--------+-----------+----------+-----------------------------------------------+\n",
      "\n",
      "+--------+-----------+----------+-----------------------------------------------+-----------------------+\n",
      "|order_id|customer_id|order_date|items                                          |exp_items              |\n",
      "+--------+-----------+----------+-----------------------------------------------+-----------------------+\n",
      "|ORD001  |CUST1001   |2023-10-01|[[P100, Laptop, 1, 1000], [P200, Mouse, 2, 25]]|[P100, Laptop, 1, 1000]|\n",
      "|ORD001  |CUST1001   |2023-10-01|[[P100, Laptop, 1, 1000], [P200, Mouse, 2, 25]]|[P200, Mouse, 2, 25]   |\n",
      "|ORD002  |CUST1002   |2023-10-02|[[P300, Monitor, 1, 300]]                      |[P300, Monitor, 1, 300]|\n",
      "+--------+-----------+----------+-----------------------------------------------+-----------------------+\n",
      "\n",
      "+--------+-----------+----------+-----------------------------------------------+-----------------------+\n",
      "|order_id|customer_id|order_date|items                                          |exp_items              |\n",
      "+--------+-----------+----------+-----------------------------------------------+-----------------------+\n",
      "|ORD001  |CUST1001   |2023-10-01|[[P100, Laptop, 1, 1000], [P200, Mouse, 2, 25]]|[P100, Laptop, 1, 1000]|\n",
      "|ORD001  |CUST1001   |2023-10-01|[[P100, Laptop, 1, 1000], [P200, Mouse, 2, 25]]|[P200, Mouse, 2, 25]   |\n",
      "|ORD002  |CUST1002   |2023-10-02|[[P300, Monitor, 1, 300]]                      |[P300, Monitor, 1, 300]|\n",
      "|ORD003  |CUST1003   |2023-10-03|[]                                             |null                   |\n",
      "+--------+-----------+----------+-----------------------------------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)\n",
    "df2.show(truncate=False)\n",
    "df3.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95862dfa",
   "metadata": {},
   "source": [
    "### Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e36e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|exp_items              |\n",
      "+-----------------------+\n",
      "|[P100, Laptop, 1, 1000]|\n",
      "|[P200, Mouse, 2, 25]   |\n",
      "|[P300, Monitor, 1, 300]|\n",
      "|null                   |\n",
      "+-----------------------+\n",
      "\n",
      "+----------+------------+--------+-----+\n",
      "|product_id|product_name|quantity|price|\n",
      "+----------+------------+--------+-----+\n",
      "|P100      |Laptop      |1       |1000 |\n",
      "|P200      |Mouse       |2       |25   |\n",
      "|P300      |Monitor     |1       |300  |\n",
      "|null      |null        |null    |null |\n",
      "+----------+------------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.select(col(\"exp_items\")).show(truncate=False)\n",
    "df3.select(col(\"exp_items.*\")).show(truncate=False) ## ----> Flattening the sturcture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52932b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+--------------------+\n",
      "|order_id|customer_id|order_date|               items|\n",
      "+--------+-----------+----------+--------------------+\n",
      "|  ORD001|   CUST1001|2023-10-01|[[P100, Laptop, 1...|\n",
      "|  ORD002|   CUST1002|2023-10-02|[[P300, Monitor, ...|\n",
      "|  ORD003|   CUST1003|2023-10-03|                  []|\n",
      "+--------+-----------+----------+--------------------+\n",
      "\n",
      "+--------+-----------+----------+--------------------+\n",
      "|order_id|customer_id|order_date|               items|\n",
      "+--------+-----------+----------+--------------------+\n",
      "|  ORD001|   CUST1001|2023-10-01|[[P100, Laptop, 1...|\n",
      "|  ORD002|   CUST1002|2023-10-02|[[P300, Monitor, ...|\n",
      "|  ORD003|   CUST1003|2023-10-03|                  []|\n",
      "+--------+-----------+----------+--------------------+\n",
      "\n",
      "+--------+-----------+----------+-----------------------------------------------+\n",
      "|order_id|customer_id|order_date|items                                          |\n",
      "+--------+-----------+----------+-----------------------------------------------+\n",
      "|ORD001  |CUST1001   |2023-10-01|[[P100, Laptop, 1, 1000], [P200, Mouse, 2, 25]]|\n",
      "|ORD002  |CUST1002   |2023-10-02|[[P300, Monitor, 1, 300]]                      |\n",
      "|ORD003  |CUST1003   |2023-10-03|[]                                             |\n",
      "+--------+-----------+----------+-----------------------------------------------+\n",
      "\n",
      "+--------+-----------+----------+-----------------------------------------------+\n",
      "|order_id|customer_id|order_date|items                                          |\n",
      "+--------+-----------+----------+-----------------------------------------------+\n",
      "|ORD001  |CUST1001   |2023-10-01|[[P100, Laptop, 1, 1000], [P200, Mouse, 2, 25]]|\n",
      "|ORD002  |CUST1002   |2023-10-02|[[P300, Monitor, 1, 300]]                      |\n",
      "|ORD003  |CUST1003   |2023-10-03|[]                                             |\n",
      "+--------+-----------+----------+-----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n",
    "df.show(10)\n",
    "df.show(truncate=False)\n",
    "df.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb0270",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "121cd105",
   "metadata": {},
   "source": [
    "### Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98a59550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+\n",
      "|region|month|sales|\n",
      "+------+-----+-----+\n",
      "| North|  Jan| 1000|\n",
      "| North|  Feb| 1100|\n",
      "| South|  Jan|  800|\n",
      "| South|  Feb|  950|\n",
      "|  East|  Jan| 1200|\n",
      "|  East|  Feb| 1300|\n",
      "+------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data_pivot_example = [\n",
    "    (\"North\", \"Jan\", 1000),\n",
    "    (\"North\", \"Feb\", 1100),\n",
    "    (\"South\", \"Jan\", 800),\n",
    "    (\"South\", \"Feb\", 950),\n",
    "    (\"East\", \"Jan\", 1200),\n",
    "    (\"East\", \"Feb\", 1300)\n",
    "]\n",
    "\n",
    "columns = [\"region\", \"month\", \"sales\"]\n",
    "\n",
    "df_pivot_source = spark.createDataFrame(data_pivot_example, columns)\n",
    "df_pivot_source.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f62bab4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----+\n",
      "|region| Feb| Jan|\n",
      "+------+----+----+\n",
      "| South| 950| 800|\n",
      "|  East|1300|1200|\n",
      "| North|1100|1000|\n",
      "+------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pivot: Convert months to columns\n",
    "pivot_df = df_pivot_source.groupBy(\"region\").pivot(\"month\").sum(\"sales\")\n",
    "\n",
    "pivot_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f322d225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+-----+\n",
      "|month|East|North|South|\n",
      "+-----+----+-----+-----+\n",
      "|  Feb|1300| 1100|  950|\n",
      "|  Jan|1200| 1000|  800|\n",
      "+-----+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pivot: Convert months to columns\n",
    "pivot_region_df = df_pivot_source.groupBy(\"month\").pivot(\"region\").sum(\"sales\")\n",
    "\n",
    "pivot_region_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e5a0f5",
   "metadata": {},
   "source": [
    "### Unpivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4110ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+\n",
      "|region|month|sales|\n",
      "+------+-----+-----+\n",
      "| South|  Jan|  800|\n",
      "| South|  Feb|  950|\n",
      "|  East|  Jan| 1200|\n",
      "|  East|  Feb| 1300|\n",
      "| North|  Jan| 1000|\n",
      "| North|  Feb| 1100|\n",
      "+------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unpivot: Convert columns Jan, Feb back to rows\n",
    "unpivot_df = pivot_df.selectExpr(\n",
    "    \"region\",\n",
    "    \"stack(2, 'Jan', Jan, 'Feb', Feb) as (month, sales)\"\n",
    ")\n",
    "\n",
    "unpivot_df.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
